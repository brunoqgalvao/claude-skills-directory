{
  "id": "story-refiner",
  "name": "\"Story Refiner\"",
  "version": "1.0.0",
  "summary": "\"Evaluates User Story quality and automatically corrects items not meeting standards. Reviews from developer, QA, and stakeholder perspectives, directly producing improved versi...",
  "description": "# Story Refiner Skill\n\n## Language Preference\n\n**Default**: Respond in the same language as the user's input or as explicitly requested by the user.\n\nIf the user specifies a preferred language (e.g., \"è«‹ç”¨ä¸­æ–‡å›žç­”\", \"Reply in Japanese\"), use that language for all outputs. Otherwise, match the language of the provided Stories.\n\n---\n\n## Role Definition\n\nYou simultaneously play three roles to review User Stories:\n\n1. **Senior Developer**: Evaluates technical feasibility and estimation clarity\n2. **QA Engineer**: Evaluates testability and acceptance criteria clarity\n3. **Product Stakeholder**: Evaluates requirement coverage and value clarity\n\n## Core Principles\n\n### Correction Over Reporting\n\n- **Don't just point out problems, directly fix them**\n- Every flagged issue must have a corresponding improved version\n- Humans only need final confirmation, not manual correction\n\n### Conservative Correction\n\n- Only correct Stories with \"obvious problems\"\n- Don't correct for the sake of correcting\n- Stories that already pass don't need changes\n\n### Transparent Annotation\n\n- Clearly explain why corrections were made\n- Provide original vs. improved version comparison\n- Let humans choose to accept or keep original version\n\n---\n\n## Input Format\n\nThis Skill accepts the following inputs:\n\n1. **Story Writer output** (recommended)\n2. **Any format User Stories list**\n3. **Original RFP + Stories** (can cross-reference coverage)\n\n---\n\n## Evaluation Criteria Reference\n\n**All scoring and evaluation must follow the standards defined in `references/evaluation-criteria.md`.**\n\nThis document defines:\n- Three scoring dimensions (Development Clarity, Testability, Value Clarity)\n- Detailed scoring criteria for each dimension (1-5 points)\n- Specific checkpoints and common deduction patterns\n- Final score calculation method\n\n**Important**: Both Quick Scan (Phase 1) and Detailed Evaluation (Phase 2) use these same criteria, with different levels of depth.\n\n---\n\n## Evaluation Flow\n\n### Phase 1: Quick Scan\n\nScore each Story initially (1-5 points) using the three dimensions from `references/evaluation-criteria.md`:\n\n**Scoring Method**:\n1. Quickly assess each dimension (Development Clarity, Testability, Value Clarity) on a 1-5 scale\n2. Calculate final score: `round((Development Clarity + Testability + Value Clarity) / 3)`\n3. Use the scoring criteria tables in `references/evaluation-criteria.md` as reference\n\n**Quick Assessment Focus**:\n- Development Clarity: Is action specific? Scope clear? Dependencies clear?\n- Testability: Can write test cases? Acceptance criteria present? Value verifiable?\n- Value Clarity: Value clear? Role correct? Maps to requirements?\n\n| Score | Level | Action |\n|-------|-------|--------|\n| 5 | Excellent | Keep, no modification |\n| 4 | Good | Keep, may have minor suggestions |\n| 3 | Passing | Mark for observation, may need minor adjustments |\n| 2 | Insufficient | **Must correct** |\n| 1 | Severely insufficient | **Must rewrite** |\n\nOnly Stories scoring â‰¤ 3 enter Phase 2 detailed evaluation.\n\n### Phase 2: Multi-Perspective Detailed Evaluation\n\nFor Stories needing review, perform detailed evaluation from three perspectives using the **Specific Checkpoints** and **Common Deduction Patterns** defined in `references/evaluation-criteria.md`.\n\n#### ðŸ‘¨â€ðŸ’» Developer Perspective\n\n**Reference**: `references/evaluation-criteria.md` - Dimension 1: Development Clarity\n\n**Detailed Checkpoints** (from evaluation-criteria.md):\n- [ ] Is action description specific?\n  - 5 points: \"Upload JPG/PNG format images, limited to 5MB\"\n  - 3 points: \"Upload images\"\n  - 1 point: \"Handle images\"\n- [ ] Does scope have boundaries?\n  - 5 points: \"Edit article title and content\"\n  - 3 points: \"Edit article\"\n  - 1 point: \"Manage articles\"\n- [ ] Are dependencies clear?\n  - 5 points: Clearly marked \"requires US-001 login feature completed first\"\n  - 3 points: Implied dependency but not marked\n  - 1 point: Confusing or circular dependencies\n\n**Common Problems** (see evaluation-criteria.md for deduction patterns):\n- Vague verbs: \"manage\", \"handle\", \"maintain\" (-1~2 points)\n- No scope boundary: \"all settings\", \"various reports\" (-1~2 points)\n- Compound features: \"create and edit\" (-1 point)\n- Technical details mixed in: \"load using AJAX\" (-1 point)\n\n#### ðŸ§ª QA Perspective\n\n**Reference**: `references/evaluation-criteria.md` - Dimension 2: Testability\n\n**Detailed Checkpoints** (from evaluation-criteria.md):\n- [ ] Are acceptance criteria clear?\n  - 5 points: Has specific Given-When-Then or checklist\n  - 3 points: Has general direction but not specific\n  - 1 point: No acceptance criteria, or vague like \"should be user-friendly\"\n- [ ] Is value verifiable?\n  - 5 points: \"so that I can find target article within 3 seconds\" (measurable)\n  - 3 points: \"so that I can find articles faster\" (relative but comparable)\n  - 1 point: \"so that I can have a better experience\" (not measurable)\n- [ ] Are error scenarios considered?\n  - 5 points: Clearly states error handling\n  - 3 points: Only happy path, but error handling can be inferred\n  - 1 point: Error scenarios completely unconsidered, and important to feature\n\n**Common Problems** (see evaluation-criteria.md for deduction patterns):\n- No acceptance criteria: None at all (-1~2 points, important features deduct more)\n- Vague criteria: \"should be fast\", \"should look good\" (-1 point)\n- Untestable value: \"so that I can have better experience\" (-2 points)\n\n#### ðŸ‘¤ Stakeholder Perspective\n\n**Reference**: `references/evaluation-criteria.md` - Dimension 3: Value Clarity\n\n**Detailed Checkpoints** (from evaluation-criteria.md):\n- [ ] Does \"so that...\" state real value?\n  - 5 points: \"so that I can pull up data within 10 seconds when customer calls\"\n  - 3 points: \"so that I can quickly view data\"\n  - 1 point: \"so that I can use this feature\" (circular reasoning)\n- [ ] Is role correct?\n  - 5 points: Role is clear and is the true beneficiary of this feature\n  - 3 points: Role too generic (e.g., \"user\" covers too much)\n  - 1 point: Wrong role (e.g., giving admin feature to regular user)\n- [ ] Maps to original requirements?\n  - 5 points: Can directly trace to a specific RFP paragraph\n  - 3 points: Is reasonably derived implied requirement\n  - 1 point: Can't see connection to original requirements\n\n**Common Problems** (see evaluation-criteria.md for deduction patterns):\n- Circular reasoning: \"so that I can use this feature\" (-2 points)\n- Role too generic: Everything is \"user\" (-1 point)\n- Technical task disguised: \"As a developer\" (-3 points)\n- Deviates from original requirements: Features RFP didn't mention (-1~2 points)\n\n### Phase 3: Auto-Correction\n\nFor Stories scoring â‰¤ 3, execute corrections based on problem type:\n\n#### Correction Strategies\n\n| Problem Type | Correction Method |\n|--------------|-------------------|\n| Scope too large | Split into multiple Stories |\n| Scope vague | Add specific operation description |\n| Value unclear | Rewrite \"so that...\" part |\n| Not testable | Add specific acceptance criteria |\n| Format issue | Adjust to standard format |\n| Wrong role | Correct to proper role |\n| Improper granularity | Split or merge |\n\n#### Correction Principles\n\n1. **Minimum change**: If small change works, don't make big changes\n2. **Preserve intent**: Don't change original requirement intent\n3. **Clear annotation**: Explain what was changed and why\n\n### Phase 4: Iterative Validation (Max 3 Rounds)\n\nCorrected Stories need re-evaluation to ensure quality meets standards. This is the core of iterative refinement.\n\n#### Why Iteration Is Needed\n\n| Situation | Single-Pass Refinement Problem | Iterative Solution |\n|-----------|-------------------------------|-------------------|\n| Story is split | New Stories aren't evaluated | âœ… Next round evaluates new Stories |\n| Over-correction | Might break something | âœ… Next round catches and fine-tunes |\n| Acceptance criteria still not specific | Passes through | âœ… Next round strengthens |\n\n#### Iteration Flow\n\n```\nRound 1: Evaluate all Stories â†’ Correct low-scoring items â†’ Produce corrected version\n    â†“\nRound 2: Evaluate \"corrected\" + \"newly generated\" Stories â†’ Correct again if needed\n    â†“\nRound 3: (If still issues) Final fine-tuning\n    â†“\nTerminate: Output final version\n```\n\n#### Termination Conditions (Stop when any is met)\n\n1. **Quality achieved**: All Stories score â‰¥ 4\n2. **No corrections needed**: This round had no Story corrections\n3. **Limit reached**: Already executed 3 rounds\n4. **Convergence failed**: Same Story corrected 2 rounds in a row but score didn't improve\n\n#### Iteration Rules\n\n| Rule | Description |\n|------|-------------|\n| **Progressive convergence** | Each round should reduce problems, not increase them |\n| **History memory** | Track each Story's correction history, avoid back-and-forth changes |\n| **Correction limit** | Same Story can only be majorly changed once, then only fine-tuned |\n| **New Story priority** | From round 2, prioritize evaluating Stories generated in previous round |\n\n#### Decreasing Correction Intensity\n\n| Round | Allowed Correction Types |\n|-------|-------------------------|\n| Round 1 | All corrections (split, rewrite, add acceptance criteria, etc.) |\n| Round 2 | Moderate corrections (add acceptance criteria, adjust wording, minor splits) |\n| Round 3 | Fine-tuning only (word corrections, add details, no splitting or rewriting) |\n\nThis design ensures:\n- Round 1 solves structural problems\n- Round 2 handles omissions and fine-tuning\n- Round 3 is just wrap-up, avoiding infinite modification\n\n#### Iteration Summary Output\n\nRecord at end of each round:\n\n```markdown\n### Round N Refinement Summary\n\n| Metric | Value |\n|--------|-------|\n| Stories Evaluated | XX |\n| Corrections Made | XX |\n| New (from splits) | XX |\n| Average Score Improvement | +X.X |\n\n**This Round's Corrections**:\n- US-XXX: [Correction summary]\n- US-XXX: [Correction summary]\n\n**Continue?**: [Yes/No, reason]\n```\n\n---\n\n## Output Format\n\n### Structure Overview\n\n```markdown\n# Story Refinement Report\n\n## ðŸ“Š Refinement Summary\n\n### Overall Results\n- Original Story Count: XX\n- Final Story Count: XX (including split additions)\n- Refinement Rounds: X / 3\n- Termination Reason: [Quality achieved / No corrections needed / Limit reached]\n\n### Per-Round Statistics\n| Round | Evaluated | Corrected | Added | Average Score |\n|-------|-----------|-----------|-------|---------------|\n| Round 1 | XX | XX | XX | X.X |\n| Round 2 | XX | XX | XX | X.X |\n| ... | ... | ... | ... | ... |\n\n## ðŸ”„ Refinement History\n[Per-round correction summaries, collapsible]\n\n## âœ… Final Passing Stories\n[Stories scoring â‰¥ 4]\n\n## ðŸ”§ Corrected Stories\n[Original â†’ Final version comparison, noting correction round]\n\n## âž• Split-Generated Stories\n[New Stories from splits]\n\n## ðŸ—‘ï¸ Recommended for Removal\n[Stories not matching requirements or duplicates]\n\n## ðŸ“‹ Final Story List\n[Complete integrated list, ready for use]\n```\n\n### Correction Detail Format\n\n```markdown\n### ðŸ”§ US-XXX: [Title]\n\n**Original Version**:\n> As a [role], I want [action], so that [value].\n\n**Problem Diagnosis**:\n- ðŸ§ª QA Perspective: Acceptance criteria unclear, can't write tests\n- ðŸ‘¨â€ðŸ’» Developer Perspective: Scope includes multiple independent features\n\n**Correction Method**: Split into two Stories + add acceptance criteria\n\n**Improved Version**:\n\n**US-XXX-A**: As a [role], I want [action A], so that [value].\n- Acceptance Criteria:\n  - [ ] Condition 1\n  - [ ] Condition 2\n\n**US-XXX-B**: As a [role], I want [action B], so that [value].\n- Acceptance Criteria:\n  - [ ] Condition 1\n\n---\n```\n\n---\n\n## Special Situation Handling\n\n### Situation 1: Large Number of Stories Need Correction (>50%)\n\nThis may indicate systematic issues in Story Writer phase:\n\n1. Don't correct one by one (too inefficient)\n2. Identify common problem patterns\n3. Propose systematic suggestions\n4. Recommend re-running Story Writer\n\n### Situation 2: Discovered Missing Features\n\nIf comparing to RFP reveals features not covered by Stories:\n\n1. Mark as \"recommended addition\"\n2. Produce suggested Story\n3. Mark source (derived from which part of RFP)\n\n### Situation 3: Discovered Duplicate Stories\n\n1. Mark duplicate items\n2. Recommend which to keep (or merge)\n3. Explain judgment basis\n\n### Situation 4: Story Quality Is Excellent\n\nIf all Stories score â‰¥ 4:\n\n1. Briefly confirm \"Quality is good, no corrections needed\"\n2. Can provide minor optimization suggestions (not mandatory)\n3. Directly output final list\n\n---\n\n## Output Example\n\nRefer to `assets/refine-example.md` for complete output example.\n\n---\n\n## Reference Documents\n\n- **Evaluation Criteria**: `references/evaluation-criteria.md` - Defines detailed scoring standards for all three dimensions\n- **Output Example**: `assets/refine-example.md` - Complete refinement report example\n\n---\n\n## Integration with Other Skills\n\n### Standard Flow\n\n```\n[rfp-analyzer] â†’ [story-writer] â†’ [story-refiner] â†’ Final output\n```\n\n**Usage**: After Story Writer produces User Stories draft, use Story Refiner to evaluate quality and automatically correct low-scoring Stories. This is a separate step that should be called explicitly when refinement is needed.\n\n---\n\n## Quality Threshold Settings\n\n### Default Threshold\n\n- Pass threshold: â‰¥ 4 points\n- Must correct: â‰¤ 2 points\n- Observation zone: 3 points (optional correction)\n\n### Strict Mode\n\nWhen user requests \"strict check\" or project risk is higher:\n\n- Pass threshold: 5 points\n- Must correct: â‰¤ 3 points\n- All Stories must have acceptance criteria\n\n### Lenient Mode\n\nWhen user requests \"quick pass\" or project is MVP/POC:\n\n- Pass threshold: â‰¥ 3 points\n- Only correct â‰¤ 1 point severe issues\n- Acceptance criteria optional\n\n---\n\n## Checklist\n\nAfter completing refinement, confirm the following items:\n\n- [ ] All Stories â‰¤ 2 points have been corrected or rewritten\n- [ ] Corrected Stories meet INVEST principles\n- [ ] Split-generated new Stories have proper numbering\n- [ ] Final list has no duplicates\n- [ ] All original requirement coverage preserved\n- [ ] Clear annotation of which are original vs. improved versions\n- [ ] Termination reason is reasonable (not forced stop from reaching limit)\n- [ ] No Story was changed back-and-forth across multiple rounds\n\n---\n\n## Iterative vs. Single-Pass Refinement\n\n### When to Use Iterative (Default)\n\n- Formal projects\n- Story count > 10\n- Has split operations\n- Higher quality requirements\n\n### When to Use Single-Pass\n\nWhen user explicitly says \"quick refine\" or \"one pass only\":\n\n- MVP/POC projects\n- Time pressure\n- Story count < 10\n- General quality requirements\n\n### Why 3 Round Limit\n\n1. **Rule of thumb**: Most problems resolved within 2 rounds\n2. **Diminishing returns**: Round 3+ corrections are usually nitpicking\n3. **Avoid over-engineering**: Infinite refinement may drift from original requirements\n4. **Time cost**: Each round requires processing time\n\nIf large numbers of low-scoring Stories remain after 3 rounds:\n1. Output current results with annotations\n2. Suggest returning to Story Writer to regenerate\n3. Analyze whether RFP itself has systematic issues",
  "verticals": [
    "engineering"
  ],
  "tags": [],
  "author": {
    "name": "bobchao",
    "github": "bobchao"
  },
  "status": "ready",
  "verified": false,
  "visibility": "public",
  "license": "MIT",
  "links": {
    "repo": "https://github.com/bobchao/pm-skills-rfp-to-stories",
    "skill_md": "https://raw.githubusercontent.com/bobchao/pm-skills-rfp-to-stories/main/story-refiner/SKILL.md"
  },
  "stats": {
    "stars": 11,
    "forks": 0,
    "installs": 0
  },
  "last_updated": "2026-01-07T12:38:47Z",
  "created_at": "2026-01-01T11:11:08Z",
  "meta": {
    "source": "github",
    "sourceUrl": "https://github.com/bobchao/pm-skills-rfp-to-stories/blob/main/story-refiner/SKILL.md",
    "harvestedAt": "2026-01-07T16:59:54.890Z",
    "uniqueId": "sk_8fc1cf52c6dc"
  }
}