{
  "id": "fact-checker",
  "name": "fact-checker",
  "version": "1.0.0",
  "summary": "Verifies factual claims in documents using web search and official sources, then proposes corrections with user confirmation. Use when the user asks to fact-check, verify inform...",
  "description": "# Fact Checker\n\nVerify factual claims in documents and propose corrections backed by authoritative sources.\n\n## When to use\n\nTrigger when users request:\n- \"Fact-check this document\"\n- \"Verify these AI model specifications\"\n- \"Check if this information is still accurate\"\n- \"Update outdated data in this file\"\n- \"Validate the claims in this section\"\n\n## Workflow\n\nCopy this checklist to track progress:\n\n```\nFact-checking Progress:\n- [ ] Step 1: Identify factual claims\n- [ ] Step 2: Search authoritative sources\n- [ ] Step 3: Compare claims against sources\n- [ ] Step 4: Generate correction report\n- [ ] Step 5: Apply corrections with user approval\n```\n\n### Step 1: Identify factual claims\n\nScan the document for verifiable statements:\n\n**Target claim types:**\n- Technical specifications (context windows, pricing, features)\n- Version numbers and release dates\n- Statistical data and metrics\n- API capabilities and limitations\n- Benchmark scores and performance data\n\n**Skip subjective content:**\n- Opinions and recommendations\n- Explanatory prose\n- Tutorial instructions\n- Architectural discussions\n\n### Step 2: Search authoritative sources\n\nFor each claim, search official sources:\n\n**AI models:**\n- Official announcement pages (anthropic.com/news, openai.com/index, blog.google)\n- API documentation (platform.claude.com/docs, platform.openai.com/docs)\n- Developer guides and release notes\n\n**Technical libraries:**\n- Official documentation sites\n- GitHub repositories (releases, README)\n- Package registries (npm, PyPI, crates.io)\n\n**General claims:**\n- Academic papers and research\n- Government statistics\n- Industry standards bodies\n\n**Search strategy:**\n- Use model names + specification (e.g., \"Claude Opus 4.5 context window\")\n- Include current year for recent information\n- Verify from multiple sources when possible\n\n### Step 3: Compare claims against sources\n\nCreate a comparison table:\n\n| Claim in Document | Source Information | Status | Authoritative Source |\n|-------------------|-------------------|--------|---------------------|\n| Claude 3.5 Sonnet: 200K tokens | Claude Sonnet 4.5: 200K tokens | ❌ Outdated model name | platform.claude.com/docs |\n| GPT-4o: 128K tokens | GPT-5.2: 400K tokens | ❌ Incorrect version & spec | openai.com/index/gpt-5-2 |\n\n**Status codes:**\n- ✅ Accurate - claim matches sources\n- ❌ Incorrect - claim contradicts sources\n- ⚠️ Outdated - claim was true but superseded\n- ❓ Unverifiable - no authoritative source found\n\n### Step 4: Generate correction report\n\nPresent findings in structured format:\n\n```markdown\n## Fact-Check Report\n\n### Summary\n- Total claims checked: X\n- Accurate: Y\n- Issues found: Z\n\n### Issues Requiring Correction\n\n#### Issue 1: Outdated AI Model Reference\n**Location:** Line 77-80 in docs/file.md\n**Current claim:** \"Claude 3.5 Sonnet: 200K tokens\"\n**Correction:** \"Claude Sonnet 4.5: 200K tokens\"\n**Source:** https://platform.claude.com/docs/en/build-with-claude/context-windows\n**Rationale:** Claude 3.5 Sonnet has been superseded by Claude Sonnet 4.5 (released Sept 2025)\n\n#### Issue 2: Incorrect Context Window\n**Location:** Line 79 in docs/file.md\n**Current claim:** \"GPT-4o: 128K tokens\"\n**Correction:** \"GPT-5.2: 400K tokens\"\n**Source:** https://openai.com/index/introducing-gpt-5-2/\n**Rationale:** 128K was output limit; context window is 400K. Model also updated to GPT-5.2\n```\n\n### Step 5: Apply corrections with user approval\n\n**Before making changes:**\n\n1. Show the correction report to the user\n2. Wait for explicit approval: \"Should I apply these corrections?\"\n3. Only proceed after confirmation\n\n**When applying corrections:**\n\n```python\n# Use Edit tool to update document\n# Example:\nEdit(\n    file_path=\"docs/03-写作规范/AI辅助写书方法论.md\",\n    old_string=\"- Claude 3.5 Sonnet: 200K tokens（约 15 万汉字）\",\n    new_string=\"- Claude Sonnet 4.5: 200K tokens（约 15 万汉字）\"\n)\n```\n\n**After corrections:**\n\n1. Verify all edits were applied successfully\n2. Note the correction summary (e.g., \"Updated 4 claims in section 2.1\")\n3. Remind user to commit changes\n\n## Search best practices\n\n### Query construction\n\n**Good queries** (specific, current):\n- \"Claude Opus 4.5 context window 2026\"\n- \"GPT-5.2 official release announcement\"\n- \"Gemini 3 Pro token limit specifications\"\n\n**Poor queries** (vague, generic):\n- \"Claude context\"\n- \"AI models\"\n- \"Latest version\"\n\n### Source evaluation\n\n**Prefer official sources:**\n1. Product official pages (highest authority)\n2. API documentation\n3. Official blog announcements\n4. GitHub releases (for open source)\n\n**Use with caution:**\n- Third-party aggregators (llm-stats.com, etc.) - verify against official sources\n- Blog posts and articles - cross-reference claims\n- Social media - only for announcements, verify elsewhere\n\n**Avoid:**\n- Outdated documentation\n- Unofficial wikis without citations\n- Speculation and rumors\n\n### Handling ambiguity\n\nWhen sources conflict:\n\n1. Prioritize most recent official documentation\n2. Note the discrepancy in the report\n3. Present both sources to the user\n4. Recommend contacting vendor if critical\n\nWhen no source found:\n\n1. Mark as ❓ Unverifiable\n2. Suggest alternative phrasing: \"According to [Source] as of [Date]...\"\n3. Recommend adding qualification: \"approximately\", \"reported as\"\n\n## Special considerations\n\n### Time-sensitive information\n\nAlways include temporal context:\n\n**Good corrections:**\n- \"截至 2026 年 1 月\" (As of January 2026)\n- \"Claude Sonnet 4.5 (released September 2025)\"\n\n**Poor corrections:**\n- \"Latest version\" (becomes outdated)\n- \"Current model\" (ambiguous timeframe)\n\n### Numerical precision\n\nMatch precision to source:\n\n**Source says:** \"approximately 1 million tokens\"\n**Write:** \"1M tokens (approximately)\"\n\n**Source says:** \"200,000 token context window\"\n**Write:** \"200K tokens\" (exact)\n\n### Citation format\n\nInclude citations in corrections:\n\n```markdown\n> **注**：具体上下文窗口以模型官方文档为准，本书写作时使用 Claude Sonnet 4.5 为主要工具。\n```\n\nLink to sources when possible.\n\n## Examples\n\n### Example 1: Technical specification update\n\n**User request:** \"Fact-check the AI model context windows in section 2.1\"\n\n**Process:**\n1. Identify claims: Claude 3.5 Sonnet (200K), GPT-4o (128K), Gemini 1.5 Pro (2M)\n2. Search official docs for current models\n3. Find: Claude Sonnet 4.5, GPT-5.2, Gemini 3 Pro\n4. Generate report showing discrepancies\n5. Apply corrections after approval\n\n### Example 2: Statistical data verification\n\n**User request:** \"Verify the benchmark scores in chapter 5\"\n\n**Process:**\n1. Extract numerical claims\n2. Search for official benchmark publications\n3. Compare reported vs. source values\n4. Flag any discrepancies with source links\n5. Update with verified figures\n\n### Example 3: Version number validation\n\n**User request:** \"Check if these library versions are still current\"\n\n**Process:**\n1. List all version numbers mentioned\n2. Check package registries (npm, PyPI, etc.)\n3. Identify outdated versions\n4. Suggest updates with changelog references\n5. Update after user confirms\n\n## Quality checklist\n\nBefore completing fact-check:\n\n- [ ] All factual claims identified and categorized\n- [ ] Each claim verified against official sources\n- [ ] Sources are authoritative and current\n- [ ] Correction report is clear and actionable\n- [ ] Temporal context included where relevant\n- [ ] User approval obtained before changes\n- [ ] All edits verified successful\n- [ ] Summary provided to user\n\n## Limitations\n\n**This skill cannot:**\n- Verify subjective opinions or judgments\n- Access paywalled or restricted sources\n- Determine \"truth\" in disputed claims\n- Predict future specifications or features\n\n**For such cases:**\n- Note the limitation in the report\n- Suggest qualification language\n- Recommend user research or expert consultation",
  "verticals": [
    "support"
  ],
  "tags": [],
  "author": {
    "name": "daymade",
    "github": "daymade"
  },
  "status": "ready",
  "verified": false,
  "visibility": "public",
  "license": "MIT",
  "links": {
    "repo": "https://github.com/daymade/claude-code-skills",
    "skill_md": "https://raw.githubusercontent.com/daymade/claude-code-skills/main/fact-checker/SKILL.md"
  },
  "stats": {
    "stars": 154,
    "forks": 13,
    "installs": 0
  },
  "last_updated": "2026-01-07T15:30:48Z",
  "created_at": "2025-10-22T11:17:31Z",
  "meta": {
    "source": "github",
    "sourceUrl": "https://github.com/daymade/claude-code-skills/blob/main/fact-checker/SKILL.md",
    "harvestedAt": "2026-01-07T16:59:54.890Z",
    "uniqueId": "sk_8b088fc3a6ce"
  }
}